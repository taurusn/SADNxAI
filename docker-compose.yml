version: '3.8'

services:
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - NEXT_PUBLIC_API_URL=https://sadnxaiapi.sadn.site/api
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=https://sadnxaiapi.sadn.site/api
    depends_on:
      - chat-service

  chat-service:
    build:
      context: .
      dockerfile: chat-service/Dockerfile
    ports:
      - "8000:8000"
    environment:
      # vLLM Configuration (default)
      - LLM_PROVIDER=${LLM_PROVIDER:-vllm}
      - VLLM_URL=http://vllm:8000
      - VLLM_API_KEY=${VLLM_API_KEY:-token-sadnxai}
      - VLLM_MODEL=${VLLM_MODEL:-meta-llama/Llama-3.1-8B-Instruct}
      # Fallback options
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - TOON_ENABLED=${TOON_ENABLED:-false}
      # Service URLs
      - REDIS_URL=redis://redis:6379/0
      - DATABASE_URL=postgresql://sadnxai:${POSTGRES_PASSWORD:-sadnxai_secure_pass}@postgres:5432/sadnxai
      - MASKING_SERVICE_URL=http://masking-service:8001
      - VALIDATION_SERVICE_URL=http://validation-service:8002
      - STORAGE_PATH=/storage
      - LLM_MOCK_MODE=${LLM_MOCK_MODE:-false}
    volumes:
      - storage:/storage
    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
      masking-service:
        condition: service_started
      validation-service:
        condition: service_started
      vllm:
        condition: service_healthy

  masking-service:
    build:
      context: .
      dockerfile: masking-service/Dockerfile
    ports:
      - "8001:8001"
    environment:
      - STORAGE_PATH=/storage
    volumes:
      - storage:/storage

  validation-service:
    build:
      context: .
      dockerfile: validation-service/Dockerfile
    ports:
      - "8002:8002"
    environment:
      - STORAGE_PATH=/storage
      - DATABASE_URL=postgresql://sadnxai:${POSTGRES_PASSWORD:-sadnxai_secure_pass}@postgres:5432/sadnxai
    volumes:
      - storage:/storage
    depends_on:
      postgres:
        condition: service_healthy

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5

  postgres:
    image: postgres:15-alpine
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=sadnxai
      - POSTGRES_USER=sadnxai
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-sadnxai_secure_pass}
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./db/init:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U sadnxai -d sadnxai"]
      interval: 5s
      timeout: 5s
      retries: 5

  vllm:
    image: vllm/vllm-openai:latest
    ports:
      - "8080:8000"
    volumes:
      - huggingface-cache:/root/.cache/huggingface
    environment:
      - HF_TOKEN=${HF_TOKEN:-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}
      - VLLM_API_KEY=${VLLM_API_KEY:-token-sadnxai}
    command: >
      --model meta-llama/Llama-3.1-8B-Instruct
      --enable-auto-tool-choice
      --tool-call-parser llama3_json
      --max-model-len 32000
      --gpu-memory-utilization 0.9
      --dtype auto
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 300s

volumes:
  storage:
  redis-data:
  postgres-data:
  huggingface-cache:
