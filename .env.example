# SADNxAI Environment Variables

# LLM Provider: vllm (recommended), ollama, or claude
LLM_PROVIDER=vllm

# vLLM settings (default provider - streaming tool calls!)
VLLM_URL=http://vllm:8000
VLLM_API_KEY=token-sadnxai
VLLM_MODEL=meta-llama/Llama-3.1-8B-Instruct

# HuggingFace token (required for gated models like Llama 3.1)
# Get yours at: https://huggingface.co/settings/tokens
HF_TOKEN=hf_xxxxx

# TOON encoding (Token-Oriented Object Notation)
TOON_ENABLED=false

# Anthropic API Key (only needed if LLM_PROVIDER=claude)
ANTHROPIC_API_KEY=sk-ant-...

# Set to 'true' to use mock LLM responses (for testing without API calls)
LLM_MOCK_MODE=false

# Redis URL (default: redis://redis:6379/0 for Docker)
REDIS_URL=redis://redis:6379/0

# Storage path (default: /storage for Docker)
STORAGE_PATH=/storage

# API URLs (for development outside Docker)
# NEXT_PUBLIC_API_URL=http://localhost:8000/api
# MASKING_SERVICE_URL=http://localhost:8001
# VALIDATION_SERVICE_URL=http://localhost:8002
